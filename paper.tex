%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Journal Article
% LaTeX Template
% Version 1.3 (9/9/13)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Frits Wenneker (http://www.howtotex.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%   PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[twoside]{article}

\usepackage[sc]{mathpazo} % Use the Palatino font
\usepackage[T1]{fontenc} % Use 8-bit encoding that has 256 glyphs
\linespread{1.05} % Line spacing - Palatino needs more space between lines
\usepackage{microtype} % Slightly tweak font spacing for aesthetics

\usepackage[hmarginratio=1:1,top=32mm,columnsep=20pt]{geometry} % Document margins
\usepackage{multicol} % Used for the two-column layout of the document
\usepackage[hang, small,labelfont=bf,up,textfont=it,up]{caption} % Custom captions under/above floats in tables or figures
\usepackage{booktabs} % Horizontal rules in tables
\usepackage{float} % Required for tables and figures in the multi-column environment - they need to be placed in specific locations with the [H] (e.g. \begin{table}[H])
\usepackage{hyperref} % For hyperlinks in the PDF

\usepackage{paralist} % Used for the compactitem environment which makes bullet points with less space between them

\usepackage{abstract} % Allows abstract customization
\renewcommand{\abstractnamefont}{\normalfont\bfseries} % Set the "Abstract" text to bold
\renewcommand{\abstracttextfont}{\normalfont\small\itshape} % Set the abstract itself to small italic text

\usepackage{titlesec} % Allows customization of titles
\renewcommand\thesection{\Roman{section}} % Roman numerals for the sections
\renewcommand\thesubsection{\Roman{subsection}} % Roman numerals for subsections
\titleformat{\section}[block]{\large\scshape\centering}{\thesection.}{1em}{} % Change the look of the section titles
\titleformat{\subsection}[block]{\large}{\thesubsection.}{1em}{} % Change the look of the section titles

\usepackage{fancyhdr} % Headers and footers
\pagestyle{fancy} % All pages have headers and footers
\fancyhead{} % Blank out the default header
\fancyfoot{} % Blank out the default footer
\fancyhead[C]{Search Algorithms for Test Job Scheduling} % Custom header text
\fancyfoot[RO,LE]{\thepage} % Custom footer text

%----------------------------------------------------------------------------------------
%   TITLE SECTION
%----------------------------------------------------------------------------------------

\title{\vspace{-15mm}\fontsize{24pt}{10pt}\selectfont
\textbf{Search Algorithms for Test Job Scheduling: Results from a Pilot Study}} % Article title

\author{
\large
\textsc{Shuai Wang, Shaukat Ali and David Buchmann}\\[2mm] % Your name
\normalsize Certus Software V\&V Center, Simula Research Laboratory, \\
\normalsize Department of Informatics and CISCO Systems \\ % Your institution
\vspace{-5mm}
}
\date{}

%----------------------------------------------------------------------------------------

\begin{document}

\maketitle % Insert title

\thispagestyle{fancy} % All pages have headers and footers

%----------------------------------------------------------------------------------------
%   ABSTRACT
%----------------------------------------------------------------------------------------

\begin{abstract}

\noindent The objective of test job scheduling techniques is to schedule test
jobs in an optimal order such that given a specific time budget a maximum
number of jobs can be executed. However, by simply ordering the jobs based on
execution time cannot ensure an optimal ordering due to several reasons; 1)
Jobs require resources before execution and setting up these resources requires
additional time; 2) Jobs with shortest execution time may not be the jobs that
have high effectiveness (e.g., coverage and fault detection capability). In
practice, there may be several tradeoff relationships among the cost and
effectiveness and such test job scheduling problem is a multi-objective
optimization problem. Search-based algorithms (e.g., (1+1) Evolutionary
Algorithm (EA)) have proven to provide an elegant solution for several multi-
objective problems. Driven by the test scheduling problem at Cisco Systems, we
define two objectives for such test job scheduling, i.e., job execution time
and resource hours (cost related to the required resources for a job) together
with test engineers at Cisco. We define a fitness function that considers both
of these objectives and is used by search algorithms to find an optimal
scheduling order. We empirically evaluate our fitness function in conjunction
with four search algorithms, i.e., (1+1)EA, Genetic Algorithm, Alternating
Variable Method, and Random Search (used as a baseline) using the provided test
database from Cisco. The results show that (1+1)EA along with our proposed
fitness function can schedule jobs by optimal order in a given time as compared
to the rest of the algorithms.

\end{abstract}

%----------------------------------------------------------------------------------------
%   ARTICLE CONTENTS
%----------------------------------------------------------------------------------------

 \begin{multicols}{2}
% Two-column layout throughout the main article text

\section{Introduction}

When running automated tests as a main means of verifying software quick
feedback is incredibly important. To facilitate quick feedback automated tests
must be run after ever commit and as the list of tests that the test system
runs grows, the strategy for allocation becomes more and more important to keep
the feedback cycle as short as possible.

We discuss different search algorithms, their effectiveness in lowering the
number of resource hours and the effect of lowering resource hours on the
number of tests that can be run.

When discussing the number of resource hours throughout this paper we will draw
many parallels to parallelization of CPU bound problems. To draw a direct
parallel, one could say (with only slight loss of generality) that the goal of
an efficient search algorithm for a test job allocation is to attempt to scale
as close to linearly when adding resources to the pool (as one would like to
when adding CPUs).


%------------------------------------------------

\section{Resource hours}

For this paper we define a term to give an equivalent to CPU hours for
resources. When allocating a specific resource to a test we assign a weight and
a cost to each resource that the test requires, the product of these two
factors gives us an idea of how large a hit the resource pool takes by
allocating this resource for the current test.

Context switching between tasks in a CPU bound problem can be expensive, and
should be minimized if possible. The equivalent is true for resource
allocation, a test requires a certain build of software on the resource, and
for it to be on a certain subnet for testing to make sense, and both these
operations take a certain amount of time depending on the type of resource in
question.

%------------------------------------------------

\section{Search algorithm}

The search algorithm will generate a list of jobs and allocated resources for
every generation we ask it to perform. Due to this, we can run it multiple
times, and can find out which generation was the most effective.

Each generation of resources for a test run must continue allocating until at
least one of the following criteria is met:

\begin{compactitem}
\item Every resource in the pool is allocated.
\item All jobs in the test queue have a resource, or an unsatisfiable required resource.
\end{compactitem}

Once a suitable number of generations have been created, one can use a fitness
function to tell us what combination of resources and jobs will yield the
lowest number of resource hours.


%------------------------------------------------

\subsection{Resource cost and Resource weight}

The cost and weight of a resource are very important factors in deciding how
scarce a resource is, and therefore whether we can afford losing it for a long
period. Here the concept of Resource hours makes a lot of sense, as we can in
some sense think of a resource of a very high cost as a very strong CPU, and so
can perform multiple (Resource) CPU hours during one hour.

The weight is calculated as a ratio of the number of resources in the pool in
relation to the others that are in the pool. After this ratio has been
calculated, we normalize the weights for one job such that:

\begin{equation}
\sum_{i}{w_{i}} = 1
\end{equation}

The effect of this normalization is that jobs that require one scarce resource
and many non scarce resources become more expensive than jobs that require
multiple scarce resources. This has the added effect that scarce resources will
be less used in non-scarce requiring jobs.

The resource cost is the cost of context switching that resource to use for the
current test. The context switch could be very cheap if the resource already
has the correct build and is on the correct subnet, or could take hours for
certain types of devices if nothing matches.

%------------------------------------------------

\subsection{Fitness function}

For the search algorithm to be able to know whether one generation of resource
allocations is better than another we need to have a fitness function. This
fitness function will give us a metric we can use to compare how long the list
of jobs will take to complete.

We propose the following fitness function for resource allocation:
\begin{equation}\label{fitness_func}
F(J, R) = \sum_{i=0}^{n}{\left( \mu \left(J_{i}\right) \cdot \sum_{j=0}^{k}{R_{j_w} \cdot R_{j_C} } \right)}
\end{equation}

\noindent $\mu (R_j)$: The average historic runtime of job index j, or max runtime (if it has
never been run) \\
\noindent $R_{j_w}$: The weight of resource j.\\
\noindent $R_{j_C}$: The cost of using resource j in the current test.

%------------------------------------------------

\section{Methods}

The following search algorithms were verified using test data supplied by CISCO:

\begin{compactitem}
\item (1+1) Evolutionary Algorithm
\item Genetic Algorithm
\item Alternating Variable Method
\item Random Search (as a baseline)
\end{compactitem}

TODO: Explanation of how each of these algorithms work.
%------------------------------------------------

\section{Results}

In this pilot study we found that the (1+1) Evolutionary Algorithm was the most
effective at running tasks.

%------------------------------------------------

\section{Discussion}

Fill in discussion

%------------------------------------------------
\end{multicols}

\end{document}
